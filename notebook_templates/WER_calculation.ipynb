{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49ffdbb-8831-41c4-a030-a3b78957b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hostname bagration not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import mne\n",
    "import torch\n",
    "import numpy as np\n",
    "import bm\n",
    "from bm import play\n",
    "from bm.train import main\n",
    "from bm.events import Word\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display as disp\n",
    "\n",
    "mne.set_log_level(False)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "os.chdir(main.dora.dir.parent)\n",
    "os.environ['NO_DOWNLOAD'] = '1'\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "from torch.nn.functional import conv2d, conv1d\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74eab8e3-a078-496a-ac4a-19fba3fc2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig='e6d65444'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddf3dec-488c-45e9-9fcd-8d9cdc5e0177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:bm.play:Loading solver from XP e6d65444. Overrides used: ['model=clip_conv', 'dset.selections=[\"gwilliams2022\"]', 'dset.bandpass=true', 'dset.bandpass_high=0.1', 'dset.bandpass_lower=40.0', 'seed=2038', 'clip.probabilities=true']\n",
      "{'wandb': {'use_wandb': True, 'project': 'brainmagick', 'group': 'brainmagick-group'}, 'num_prints': 5, 'device': 'cuda:0', 'verbose': 0, 'show': 0, 'download_only': False, 'is_sound': True, 'slurm': {'mem_per_gpu': 100, 'time': 4320}, 'continue_sig': None, 'continue_best': True, 'seed': 2038, 'dummy': None, 'cache': '/home/zubrikhina/brainmagick_MICCAI/cache', 'features_models': './features_models', 'early_stop_patience': 10, 'eval_every': 1, 'eval_train_set': False, 'optim': {'name': 'adam', 'shuffle': False, 'lr': 0.0003, 'beta2': 0.999, 'eps': 1e-08, 'epochs': 200, 'batch_size': 256, 'loss': 'clip', 'weight_decay': 0.0, 'use_weighting': False, 'max_batches': 1200, 'svd': 0.0, 'negatives': None, 'negative_pool_size': None, 'scheduler': {'name': 'None'}}, 'clip': {'linear': None, 'twin': True, 'pool': False, 'tmin': None, 'tmax': None, 'tmin_train': None, 'tmax_train': None, 'center': False, 'probabilities': True}, 'test': {'wer_negatives': 10000, 'wer_topx': 10, 'wer_random': False, 'wer_recordings': 40, 'wer_study': None}, 'dset': {'selections': ['gwilliams2022'], 'tmin': -0.5, 'tmax': 2.5, 'n_recordings': 1000, 'n_subjects': None, 'n_subjects_test': None, 'shuffle_recordings_seed': -1, 'skip_recordings': 0, 'test_ratio': 0.2, 'valid_ratio': 0.1, 'remove_ratio': 0.0, 'condition': 0.5, 'apply_baseline': True, 'min_block_duration': 6, 'force_uid_assignement': False, 'min_n_blocks_per_split': 1, 'ignore_end_in_block': False, 'ignore_start_in_block': False, 'sample_rate': 120, 'highpass': 0, 'bandpass': True, 'bandpass_high': 0.1, 'bandpass_lower': 40.0, 'event_mask': True, 'split_wav_as_block': True, 'allow_empty_split': False, 'autoreject': False, 'test': {'tmin': None, 'tmax': None, 'condition': 'word'}, 'features': ['Wav2VecTransformer'], 'extra_test_features': [], 'features_params': {'MelSpectrum': {'n_fft': 512, 'n_mels': 120, 'normalized': True, 'use_log_scale': True, 'log_scale_eps': 1e-05}, 'Pitch': {'min_f0': 100, 'max_f0': 350}, 'WordHash': {'buckets': 100000}, 'XlmEmbedding': {'contextual': False}, 'WordEmbedding': {'lang': 'auto'}, 'WordEmbeddingSmall': {'lang': 'auto'}, 'PartOfSpeech': {'lang': 'auto'}, 'Wav2VecTransformer': {'layers': [14, 15, 16, 17, 18], 'device': 'cpu', 'random': False, 'is_interpolate': True, 'size': 150}, 'Wav2VecChunk': {'device': 'cpu'}}}, 'override_n_subjects_model': None, 'norm': {'scaler': {'per_channel': False, 'n_samples_per_recording': 200, 'n_samples_features': 8000}, 'max_scale': 20.0, 'clip': True, 'exclude_empty_features': False}, 'task': {'type': 'decode', 'meg_init': 0.3, 'lowpass': 0, 'offset_meg_ms': 150, 'lowpass_gt': True, 'lowpass_gt_test': False, 'mask_loss': False}, 'dora': {'dir': './outputs', 'exclude': ['wandb.*', 'num_prints', 'device', 'num_workers', 'verbose', 'cache', 'features_models'], 'git_save': True}, 'model_name': 'simpleconv', 'convrnn': {'concatenate': False, 'depth': 2, 'linear_out': False, 'complex_out': False, 'kernel_size': 4, 'stride': 2, 'growth': 1.0, 'lstm': 4, 'bidirectional_lstm': False, 'flip_lstm': False, 'attention': 0, 'heads': 4, 'conv_dropout': 0.0, 'lstm_dropout': 0.0, 'dropout_input': 0.0, 'batch_norm': False, 'relu_leakiness': 0.0, 'subject_dim': 64, 'embedding_location': ['lstm'], 'embedding_scale': 1.0, 'subject_layers': False, 'subject_layers_dim': 'input'}, 'simpleconv': {'concatenate': False, 'depth': 10, 'linear_out': False, 'complex_out': True, 'dilation_growth': 2, 'dilation_period': 5, 'skip': True, 'post_skip': False, 'growth': 1.0, 'scale': None, 'rewrite': False, 'groups': 1, 'glu': 2, 'glu_context': 1, 'glu_glu': True, 'gelu': True, 'dual_path': 0, 'conv_dropout': 0.0, 'dropout_input': 0.0, 'batch_norm': True, 'relu_leakiness': 0.0, 'subject_dim': 0, 'subject_layers': True, 'embedding_scale': 1.0, 'subject_layers_dim': 'input', 'subject_layers_id': False, 'n_fft': None, 'fft_complex': True, 'merger': True, 'merger_pos_dim': 2048, 'merger_channels': 270, 'merger_dropout': 0.2, 'merger_penalty': 0.0, 'merger_per_subject': False, 'dropout': 0.0, 'dropout_rescale': True, 'initial_linear': 270, 'initial_depth': 1, 'initial_nonlin': False, 'avg_pool_out': False, 'adaptive_pooling_size': 1, 'flatten_out_channels': 512, 'strides': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'kernel_size': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'padding': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'seq_len': -1, 'auto_padding': True, 'is_deformable_conv': False, 'hidden': {'meg': 320}, 'flatten_out': False}, 'simpletransformer': {'hidden': {'meg': 320}, 'depth': 4, 'nhead': 8, 'subject_layers': False, 'positional_embedding': False, 'merger': False, 'merger_pos_dim': 2048, 'merger_channels': 272, 'model_type': 'basic', 'dim_ff': 2048, 'attention_window': [32, 32, 32, 32]}, 'timesnet': {'hidden': {'meg': 320}, 'depth': 2, 'subject_layers': False, 'sequence_lenth': 361, 'num_kernels': 6, 'top_k': 3, 'dropout_projection': 0.3, 'd_model': 32, 'd_ff': 32, 'flatten_out_channels': 1024, 'merger': False, 'merger_pos_dim': 2048, 'merger_channels': 270, 'enc_embedding': True}, 'cnntransformer': {'hidden': {'meg': 320}, 'batch_norm': True, 'depth': 4, 'dilation_period': 4, 'skip': True, 'subject_layers': True, 'subject_dim': 0, 'complex_out': True, 'glu': 2, 'glu_context': 1, 'merger': True, 'initial_linear': 270, 'gelu': True, 'merger_pos_dim': 2048, 'avg_pool_out': False, 'adaptive_pooling_size': 1, 'flatten_out': True, 'flatten_out_channels': 264, 'strides': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'conv_dropout': 0.0, 'kernel_size': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'padding': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'seq_len': 361, 'auto_padding': True, 'is_deformable_conv': False, 'in_channels_tranformer': 264, 'out_channels_transformer': 1024, 'dim_ff': 2048, 'nhead': 8, 'positional_embedding': 'False,', 'positional_embedding_dropout': 0.0}, 'num_workers': 5, 'feature_model_name': None, 'selections': {'audio_mous': {'study': 'schoffelen2019', 'modality': 'audio', 'events_filter': None}, 'audio_mous_wl': {'study': 'schoffelen2019', 'modality': 'audio', 'events_filter': 'condition == \"word_list\"'}, 'visual_mous': {'study': 'schoffelen2019', 'modality': 'visual', 'events_filter': None}, 'gwilliams2022': {'study': 'gwilliams2022'}, 'broderick2019': {'study': 'broderick2019'}, 'fake': {'study': 'fake'}, 'brennan2019': {'study': 'brennan2019'}}, 'study_paths': {'default': {'gwilliams2022': './data/gwilliams2022/', 'schoffelen2019': './data/schoffelen2019/', 'brennan2019': './data/brennan2019/', 'broderick2019': './data/broderick2019/'}}}\n",
      "WARNING:bm._env:Hostname bagration not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
      "WARNING:bm.dataset:Requested 1000 recordings but only found 196\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 1/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 2/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 5/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 6/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 9/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 10/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 13/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 14/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 17/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 18/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 21/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 22/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 25/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 26/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 29/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 30/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 33/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 34/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 37/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 38/196.\n",
      "INFO:bm.dataset:Loading Subjects | 39/196 | 0.26 it/sec\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 41/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 42/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 45/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 46/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 49/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 50/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 53/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 54/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 57/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 58/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 61/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 62/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 65/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 66/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 69/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 70/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 73/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 74/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 77/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 78/196.\n",
      "INFO:bm.dataset:Loading Subjects | 78/196 | 0.28 it/sec\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 81/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 82/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 85/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 86/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 89/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 90/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 93/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 94/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 97/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 98/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 101/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 102/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 105/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 106/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 109/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 110/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 113/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 114/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 117/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 118/196.\n",
      "INFO:bm.dataset:Loading Subjects | 117/196 | 0.29 it/sec\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 121/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 122/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 125/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 126/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 129/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 130/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 133/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 134/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 137/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 138/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 141/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 142/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 145/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 146/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 149/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 150/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 153/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 154/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 157/196.\n",
      "INFO:bm.dataset:Loading Subjects | 156/196 | 0.30 it/sec\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 158/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 161/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 162/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 165/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 166/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 169/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 170/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 173/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 174/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 177/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 178/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 181/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 182/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 185/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 186/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 189/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 190/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 193/196.\n",
      "WARNING:bm.dataset:No blocks found for split 2/3 of recording 194/196.\n",
      "INFO:bm.dataset:Loading Subjects | 195/196 | 0.31 it/sec\n",
      "INFO:bm.dataset:# Examples (train | valid | test): 314922 | 37249 | 55223\n",
      "1024\n",
      "INFO:bm.train:Model hash: 9d7596cc30c08ea9f05eea96ce06b6f5e10064b6\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zubrikhina/anaconda3/envs/bm/lib/python3.8/site-packages/flashy/loggers/tensorboard.py:47: UserWarning: tensorboard package was not found: use pip install tensorboard\n",
      "  warnings.warn(\"tensorboard package was not found: use pip install tensorboard\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malmachan2358\u001b[0m (\u001b[33mgnn-neuro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/zubrikhina/brainmagick_MICCAI/outputs/xps/e6d65444/wandb/run-20240306_184232-e6d65444</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/gnn-neuro/brainmagick/runs/e6d65444' target=\"_blank\">e6d65444</a></strong> to <a href='https://wandb.ai/gnn-neuro/brainmagick' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gnn-neuro/brainmagick' target=\"_blank\">https://wandb.ai/gnn-neuro/brainmagick</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gnn-neuro/brainmagick/runs/e6d65444' target=\"_blank\">https://wandb.ai/gnn-neuro/brainmagick/runs/e6d65444</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solver = play.get_solver_from_sig(sig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f7fe02-83c6-4aad-8472-7e124f8a3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bm.wer import get_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee58b53-64e6-4280-8fd1-30d0873b8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.args.test.wer_topx =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd86af6-226a-4885-9125-d0f2f821e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.ConcatDataset at 0x7f134a9977c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.datasets.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37fb8c64-88e4-4854-9b79-fab14b16a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:bm.wer:WER | 9/45 | 0.21 it/sec\n",
      "INFO:bm.wer:WER | 18/45 | 0.27 it/sec\n",
      "INFO:bm.wer:WER | 27/45 | 0.30 it/sec\n",
      "INFO:bm.wer:WER | 36/45 | 0.32 it/sec\n",
      "INFO:bm.wer:wer 10000 negatives selected\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 13.09 GiB. GPU 0 has a total capacty of 47.51 GiB of which 11.08 GiB is free. Process 335503 has 34.40 GiB memory in use. Including non-PyTorch memory, this process has 2.02 GiB memory in use. Of the allocated memory 1006.46 MiB is allocated by PyTorch, and 539.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_wer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/brainmagick_MICCAI/bm/wer.py:81\u001b[0m, in \u001b[0;36mget_wer\u001b[0;34m(solver, dataset)\u001b[0m\n\u001b[1;32m     78\u001b[0m     negative_hashes \u001b[38;5;241m=\u001b[39m word_hashes\n\u001b[1;32m     79\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwer \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m negatives selected\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(negatives))\n\u001b[0;32m---> 81\u001b[0m negatives \u001b[38;5;241m=\u001b[39m \u001b[43mnegatives\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m negative_hashes \u001b[38;5;241m=\u001b[39m negative_hashes\u001b[38;5;241m.\u001b[39mto(solver\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     83\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 13.09 GiB. GPU 0 has a total capacty of 47.51 GiB of which 11.08 GiB is free. Process 335503 has 34.40 GiB memory in use. Including non-PyTorch memory, this process has 2.02 GiB memory in use. Of the allocated memory 1006.46 MiB is allocated by PyTorch, and 539.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "get_wer(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455dc7b6-7bf1-482c-b195-0494569fed8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
