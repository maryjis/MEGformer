{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173db5a6-1b24-495f-8257-7af44036f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hostname bagration not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import mne\n",
    "import torch\n",
    "import numpy as np\n",
    "import bm\n",
    "from bm import play\n",
    "from bm.train import main\n",
    "from bm.events import Word\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display as disp\n",
    "\n",
    "mne.set_log_level(False)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "os.chdir(main.dora.dir.parent)\n",
    "os.environ['NO_DOWNLOAD'] = '1'\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "from torch.nn.functional import conv2d, conv1d\n",
    "import torch.nn.functional as F\n",
    "from bm.losses import ClipLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17dd4c6-ef88-43c1-b38b-510cc7716ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig='342eaad6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cbc492-c8cf-490d-94f0-6b4a2795c9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:bm.play:Loading solver from XP 342eaad6. Overrides used: ['model=clip_conv', 'dset.selections=[\"gwilliams2022\"]', 'dset.bandpass=true', 'dset.bandpass_high=0.1', 'dset.bandpass_lower=40.0', 'seed=2038', 'dset.tmin=-0.75', 'dset.tmax=3.25']\n",
      "{'wandb': {'use_wandb': True, 'project': 'brainmagick', 'group': 'brainmagick-group'}, 'num_prints': 5, 'device': 'cuda:1', 'num_workers': 5, 'verbose': 0, 'show': 0, 'download_only': False, 'slurm': {'mem_per_gpu': 100, 'time': 4320}, 'continue_sig': None, 'continue_best': True, 'seed': 2038, 'dummy': None, 'cache': '/home/zubrikhina/brainmagick_MICCAI/cache', 'features_models': './features_models', 'early_stop_patience': 10, 'eval_every': 1, 'eval_train_set': False, 'optim': {'name': 'adam', 'shuffle': False, 'lr': 0.0003, 'beta2': 0.999, 'epochs': 200, 'batch_size': 256, 'loss': 'clip', 'weight_decay': 0.0, 'use_weighting': False, 'max_batches': 1200, 'svd': 0.0, 'negatives': None, 'negative_pool_size': None}, 'clip': {'linear': None, 'twin': True, 'pool': False, 'tmin': None, 'tmax': None, 'tmin_train': None, 'tmax_train': None, 'center': False, 'probabilities': False}, 'test': {'wer_negatives': 10000, 'wer_topx': 10, 'wer_random': False, 'wer_recordings': 40, 'wer_study': None}, 'dset': {'selections': ['gwilliams2022'], 'tmin': -0.75, 'tmax': 3.25, 'n_recordings': 1000, 'n_subjects': None, 'n_subjects_test': None, 'shuffle_recordings_seed': -1, 'skip_recordings': 0, 'test_ratio': 0.2, 'valid_ratio': 0.1, 'remove_ratio': 0.0, 'condition': 0.5, 'apply_baseline': True, 'min_block_duration': 6, 'force_uid_assignement': False, 'min_n_blocks_per_split': 1, 'ignore_end_in_block': False, 'ignore_start_in_block': False, 'sample_rate': 120, 'highpass': 0, 'bandpass': True, 'bandpass_high': 0.1, 'bandpass_lower': 40.0, 'event_mask': True, 'split_wav_as_block': True, 'allow_empty_split': False, 'autoreject': False, 'test': {'tmin': None, 'tmax': None, 'condition': 'word'}, 'features': ['Wav2VecTransformer'], 'extra_test_features': [], 'features_params': {'MelSpectrum': {'n_fft': 512, 'n_mels': 120, 'normalized': True, 'use_log_scale': True, 'log_scale_eps': 1e-05}, 'Pitch': {'min_f0': 100, 'max_f0': 350}, 'WordHash': {'buckets': 100000}, 'XlmEmbedding': {'contextual': False}, 'WordEmbedding': {'lang': 'auto'}, 'WordEmbeddingSmall': {'lang': 'auto'}, 'PartOfSpeech': {'lang': 'auto'}, 'Wav2VecTransformer': {'layers': [14, 15, 16, 17, 18], 'device': 'cpu', 'random': False}, 'Wav2VecChunk': {'device': 'cpu'}}}, 'override_n_subjects_model': None, 'norm': {'scaler': {'per_channel': False, 'n_samples_per_recording': 200, 'n_samples_features': 8000}, 'max_scale': 20.0, 'clip': True, 'exclude_empty_features': False}, 'task': {'type': 'decode', 'meg_init': 0.3, 'lowpass': 0, 'offset_meg_ms': 150, 'lowpass_gt': True, 'lowpass_gt_test': False, 'mask_loss': False}, 'dora': {'dir': './outputs', 'exclude': ['wandb.*', 'num_prints', 'device', 'num_workers', 'verbose', 'cache', 'features_models'], 'git_save': True}, 'model_name': 'simpleconv', 'convrnn': {'concatenate': False, 'depth': 2, 'linear_out': False, 'complex_out': False, 'kernel_size': 4, 'stride': 2, 'growth': 1.0, 'lstm': 4, 'bidirectional_lstm': False, 'flip_lstm': False, 'attention': 0, 'heads': 4, 'conv_dropout': 0.0, 'lstm_dropout': 0.0, 'dropout_input': 0.0, 'batch_norm': False, 'relu_leakiness': 0.0, 'subject_dim': 64, 'embedding_location': ['lstm'], 'embedding_scale': 1.0, 'subject_layers': False, 'subject_layers_dim': 'input'}, 'simpleconv': {'concatenate': False, 'depth': 10, 'linear_out': False, 'complex_out': True, 'kernel_size': 3, 'dilation_growth': 2, 'dilation_period': 5, 'skip': True, 'post_skip': False, 'growth': 1.0, 'scale': None, 'rewrite': False, 'groups': 1, 'glu': 2, 'glu_context': 1, 'glu_glu': True, 'gelu': True, 'dual_path': 0, 'conv_dropout': 0.0, 'dropout_input': 0.0, 'batch_norm': True, 'relu_leakiness': 0.0, 'subject_dim': 0, 'subject_layers': True, 'embedding_scale': 1.0, 'subject_layers_dim': 'input', 'subject_layers_id': False, 'n_fft': None, 'fft_complex': True, 'merger': True, 'merger_pos_dim': 2048, 'merger_channels': 270, 'merger_dropout': 0.2, 'merger_penalty': 0.0, 'merger_per_subject': False, 'dropout': 0.0, 'dropout_rescale': True, 'initial_linear': 270, 'initial_depth': 1, 'initial_nonlin': False, 'avg_pool_out': False, 'adaptive_pooling_size': 1, 'flatten_out_channels': 512, 'strides': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'hidden': {'meg': 320}, 'flatten_out': False}, 'simpletransformer': {'hidden': {'meg': 320}, 'depth': 4, 'nhead': 8, 'subject_layers': False, 'positional_embedding': False, 'merger': False, 'merger_pos_dim': 2048, 'merger_channels': 272, 'model_type': 'basic', 'dim_ff': 2048, 'attention_window': [32, 32, 32, 32]}, 'timesnet': {'hidden': {'meg': 320}, 'depth': 2, 'subject_layers': False, 'sequence_lenth': 361, 'num_kernels': 6, 'top_k': 3, 'dropout_projection': 0.3, 'd_model': 32, 'd_ff': 32, 'flatten_out_channels': 1024, 'merger': False, 'merger_pos_dim': 2048, 'merger_channels': 270, 'enc_embedding': True}, 'feature_model_name': None, 'selections': {'audio_mous': {'study': 'schoffelen2019', 'modality': 'audio', 'events_filter': None}, 'audio_mous_wl': {'study': 'schoffelen2019', 'modality': 'audio', 'events_filter': 'condition == \"word_list\"'}, 'visual_mous': {'study': 'schoffelen2019', 'modality': 'visual', 'events_filter': None}, 'gwilliams2022': {'study': 'gwilliams2022'}, 'broderick2019': {'study': 'broderick2019'}, 'fake': {'study': 'fake'}, 'brennan2019': {'study': 'brennan2019'}}, 'study_paths': {'default': {'gwilliams2022': './data/gwilliams2022/', 'schoffelen2019': './data/schoffelen2019/', 'brennan2019': './data/brennan2019/', 'broderick2019': './data/broderick2019/'}}}\n",
      "WARNING:bm._env:Hostname bagration not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
      "WARNING:bm.dataset:Requested 1000 recordings but only found 196\n",
      "INFO:bm.dataset:Loading Subjects | 39/196 | 0.44 it/sec\n",
      "INFO:bm.dataset:Loading Subjects | 78/196 | 0.44 it/sec\n",
      "INFO:bm.dataset:Loading Subjects | 117/196 | 0.44 it/sec\n",
      "INFO:bm.dataset:Loading Subjects | 156/196 | 0.44 it/sec\n",
      "INFO:bm.dataset:Loading Subjects | 195/196 | 0.44 it/sec\n",
      "INFO:bm.dataset:# Examples (train | valid | test): 179864 | 30380 | 60172\n",
      "SimpleConv(\n",
      "  (merger): ChannelMerger(\n",
      "    (embedding): FourierEmb()\n",
      "  )\n",
      "  (initial_linear): Sequential(\n",
      "    (0): Conv1d(270, 270, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (subject_layers): SubjectLayers(270, 270, 27)\n",
      "  (final): Sequential(\n",
      "    (0): Conv1d(320, 640, kernel_size=(1,), stride=(1,))\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): ConvTranspose1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (encoders): ModuleDict(\n",
      "    (meg): ConvSequence(\n",
      "      (sequence): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv1d(270, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (8): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (9): Sequential(\n",
      "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "      )\n",
      "      (glus): ModuleList(\n",
      "        (0): None\n",
      "        (1): Sequential(\n",
      "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): GLU(dim=1)\n",
      "        )\n",
      "        (2): None\n",
      "        (3): Sequential(\n",
      "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): GLU(dim=1)\n",
      "        )\n",
      "        (4): None\n",
      "        (5): Sequential(\n",
      "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): GLU(dim=1)\n",
      "        )\n",
      "        (6): None\n",
      "        (7): Sequential(\n",
      "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): GLU(dim=1)\n",
      "        )\n",
      "        (8): None\n",
      "        (9): Sequential(\n",
      "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): GLU(dim=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "INFO:bm.train:Model hash: 9d7596cc30c08ea9f05eea96ce06b6f5e10064b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zubrikhina/anaconda3/envs/bm/lib/python3.8/site-packages/flashy/loggers/tensorboard.py:47: UserWarning: tensorboard package was not found: use pip install tensorboard\n",
      "  warnings.warn(\"tensorboard package was not found: use pip install tensorboard\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malmachan2358\u001b[0m (\u001b[33mgnn-neuro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/zubrikhina/brainmagick_MICCAI/outputs/xps/342eaad6/wandb/run-20240131_195431-342eaad6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/gnn-neuro/brainmagick/runs/342eaad6' target=\"_blank\">342eaad6</a></strong> to <a href='https://wandb.ai/gnn-neuro/brainmagick' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gnn-neuro/brainmagick' target=\"_blank\">https://wandb.ai/gnn-neuro/brainmagick</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gnn-neuro/brainmagick/runs/342eaad6' target=\"_blank\">https://wandb.ai/gnn-neuro/brainmagick/runs/342eaad6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solver = play.get_solver_from_sig(sig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683891d0-5537-4b59-b7ed-b2370ae3b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip =ClipLoss(probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b352215-e3c8-424c-b10f-faf04ae567dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_one_segments_and_vocabs(solver):\n",
    "    from scripts.run_eval_probs import _get_extra_info\n",
    "    split ='train'\n",
    "    segments,vocab, estimates,outputs,features_masks, reject_masks = [], [],[], [],[], []\n",
    "    dset = getattr(solver.datasets, split)\n",
    "    loader = solver.make_loader(dset, shuffle=False)\n",
    "    test_features = solver.datasets.test.datasets[0].features\n",
    "    for idx, batch in tqdm(enumerate(loader)):\n",
    "        #features = test_features.extract_features(batch.features, solver.used_features.keys())\n",
    "        with torch.no_grad():\n",
    "            estimate, output, features_mask, reject_mask = solver._process_batch(batch)\n",
    "            data,  words, word_segs= _get_extra_info(batch, solver.args.dset.sample_rate)\n",
    "        if idx>1:\n",
    "            break\n",
    "    return batch,features_mask, estimate, output, word_segs,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81210726-69d9-4340-a392-39c81896fb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:11,  5.65s/it]\n"
     ]
    }
   ],
   "source": [
    "batch,features_mask, estimate, output, word_segs,vocab = _get_one_segments_and_vocabs(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3589ece6-28c8-4382-b1d7-63b5c67586a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft-clip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6602, device='cuda:1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.forward(estimate, output,features_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae739ab-65ad-4b66-9746-422dd94263e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClipLoss()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12302f5-44cd-4e09-b4b6-eb9fa24e05c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
