{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import mne\n",
    "import torch\n",
    "import numpy as np\n",
    "import bm\n",
    "from bm import play\n",
    "from bm.train import main\n",
    "from bm.events import Word\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display as disp\n",
    "\n",
    "mne.set_log_level(False)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "os.chdir(main.dora.dir.parent)\n",
    "os.environ['NO_DOWNLOAD'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigs = ['34219380', '6e3bf7d7', '557f5f8a', '4395629c']\n",
    "sig = '342eaad6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_segments_and_vocabs(solver):\n",
    "    from scripts.run_eval_probs import _get_extra_info\n",
    "    per_split = {}\n",
    "    for split in ['train', 'test']:\n",
    "        segments = set()\n",
    "        sentences = set()\n",
    "        vocab = set()\n",
    "        dset = getattr(solver.datasets, split)\n",
    "        loader = solver.make_loader(dset, shuffle=False)\n",
    "        for idx, batch in enumerate(loader):\n",
    "            data, *_ = _get_extra_info(batch, solver.args.dset.sample_rate)\n",
    "            time_to_main_word = 0 - solver.args.dset.tmin  # location of main word relative to segment start\n",
    "            # e.g. with MNE we have tmin=-0.5 so the main word is 0.5 seconds after start of MNE Epoch.\n",
    "            margin = 2 # we need to look a bit after 0.5 due to rounding error, this is in time steps.\n",
    "            look_at_index = int(time_to_main_word * solver.args.dset.sample_rate + margin)\n",
    "            word_index = data[:, 0, look_at_index]\n",
    "            sequence_id = data[:, 1, look_at_index]\n",
    "            segment_ids = list(zip(word_index.tolist(), sequence_id.tolist()))\n",
    "            \n",
    "            segment_duration = data.shape[-1] / solver.args.dset.sample_rate\n",
    "            for events in batch._event_lists:\n",
    "                for event in events:\n",
    "                    if isinstance(event, Word):\n",
    "                        start = event.start - events[0].start\n",
    "                        end = start + event.duration\n",
    "                        if end > 0.02 and start < segment_duration - 0.02:\n",
    "                            # due to rounding errors, retrieval of related events\n",
    "                            # can sometime overlap in a non meaningful way, e.g. less than 20ms.\n",
    "                            # we only consider an event if it overlaps for at least 20ms.\n",
    "                            sentences.add(event.word_sequence)\n",
    "                            vocab.add(event.word)\n",
    "            segments |= set(segment_ids)\n",
    "#             print(idx, len(loader), end='\\r')\n",
    "#         print(split, \"done\", \" \" * 400)\n",
    "        per_split[split] = (segments, vocab, sentences)\n",
    "    return per_split\n",
    "\n",
    "\n",
    "def print_table_line(solver):\n",
    "    channels = solver.datasets.train[0].meg.shape[0]\n",
    "    n_subjects = len(set([dataset.recording.subject_uid for dataset in solver.datasets.train.datasets]))\n",
    "    per_split = _get_segments_and_vocabs(solver)\n",
    "    assert len(solver.args.dset.selections) == 1\n",
    "    name = solver.args.dset.selections[0]\n",
    "    duration = 0.\n",
    "    for dset in solver.datasets.train.datasets:\n",
    "        events = dset.recording.events()\n",
    "        duration += (events.start + events.duration).max()\n",
    "    \n",
    "    print(name, channels, '&' , n_subjects, '&', format(duration/ 3600, '.1f') + ' h', end='')\n",
    "    for split in ('train', 'test'):\n",
    "        segments, vocab, sentences = per_split[split]\n",
    "        print('&', len(segments), '&', len(vocab), end='')\n",
    "    vocab_train = per_split['train'][1]\n",
    "    vocab_test = per_split['test'][1]\n",
    "    vocab_overlap = len(vocab_train & vocab_test) / len(vocab_test)\n",
    "#     print('&', format(vocab_overlap, '.1%'), end='')\n",
    "    print(r'\\\\')\n",
    "    print(\"Vocab overlap:\", format(vocab_overlap, '.1%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:bm.play:Loading solver from XP 342eaad6. Overrides used: ['model=clip_conv', 'dset.selections=[\"gwilliams2022\"]', 'dset.bandpass=true', 'dset.bandpass_high=0.1', 'dset.bandpass_lower=40.0', 'seed=2038', 'dset.tmin=-0.75', 'dset.tmax=3.25']\n",
      "WARNING:bm._env:Hostname d26ce98a77d4 not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
      "WARNING:bm.dataset:Requested 1000 recordings but only found 196\n",
      "INFO:bm.dataset:Loading Subjects | 39/196 | 0.43 it/sec\n",
      "INFO:bm.dataset:Loading Subjects | 78/196 | 0.43 it/sec\n",
      "INFO:bm.dataset:Loading Subjects | 117/196 | 0.42 it/sec\n",
      "INFO:bm.dataset:Loading Subjects | 156/196 | 0.42 it/sec\n",
      "INFO:bm.dataset:Loading Subjects | 195/196 | 0.42 it/sec\n",
      "INFO:bm.dataset:# Examples (train | valid | test): 179864 | 30380 | 60172\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "/home/zubrikhina/brainmagick_MICCAI/data/gwilliams2022/download/stimuli/audio/lw1_0.wav does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m solver \u001b[38;5;241m=\u001b[39m play\u001b[38;5;241m.\u001b[39mget_solver_from_sig(sig)\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/play.py:70\u001b[0m, in \u001b[0;36mget_solver_from_sig\u001b[0;34m(sig, override_cfg)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m main\n\u001b[1;32m     69\u001b[0m xp \u001b[38;5;241m=\u001b[39m main\u001b[38;5;241m.\u001b[39mget_xp_from_sig(sig)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_solver_from_xp(xp, override_cfg\u001b[38;5;241m=\u001b[39moverride_cfg)\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/play.py:56\u001b[0m, in \u001b[0;36mget_solver_from_xp\u001b[0;34m(xp, override_cfg)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m xp\u001b[38;5;241m.\u001b[39menter():\n\u001b[0;32m---> 56\u001b[0m         solver \u001b[38;5;241m=\u001b[39m get_solver(args, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     57\u001b[0m     solver\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m solver\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/train.py:59\u001b[0m, in \u001b[0;36mget_solver\u001b[0;34m(args, training)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdownload_only:\n\u001b[1;32m     57\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m meg_dimension \u001b[38;5;241m=\u001b[39m dsets\u001b[38;5;241m.\u001b[39mtrain[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmeg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     60\u001b[0m used_features \u001b[38;5;241m=\u001b[39m dsets\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mdatasets[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py:302\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/dataset.py:366\u001b[0m, in \u001b[0;36mSegmentDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeg_dimension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m         meg_torch \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(meg_torch, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeg_dimension \u001b[38;5;241m-\u001b[39m meg_torch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m--> 366\u001b[0m     feature_data, feature_mask, events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_feature(index)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SegmentBatch(\n\u001b[1;32m    368\u001b[0m         meg\u001b[38;5;241m=\u001b[39mmeg_torch,\n\u001b[1;32m    369\u001b[0m         features\u001b[38;5;241m=\u001b[39mfeature_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m         _event_lists\u001b[38;5;241m=\u001b[39m[events],\n\u001b[1;32m    375\u001b[0m     )\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/dataset.py:355\u001b[0m, in \u001b[0;36mSegmentDataset._get_feature\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the feature corresponding to index idx\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m start, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bounds_times(idx)\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(start, stop)\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/features/base.py:92\u001b[0m, in \u001b[0;36mFeaturesBuilder.__call__\u001b[0;34m(self, start, stop)\u001b[0m\n\u001b[1;32m     88\u001b[0m dslice \u001b[38;5;241m=\u001b[39m DataSlice(\n\u001b[1;32m     89\u001b[0m     start\u001b[38;5;241m=\u001b[39mstart, duration\u001b[38;5;241m=\u001b[39mstop \u001b[38;5;241m-\u001b[39m start, sample_rate\u001b[38;5;241m=\u001b[39msample_rate,\n\u001b[1;32m     90\u001b[0m     language\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, modality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# XXX To remove when migrating to Python 3.10\u001b[39;00m\n\u001b[1;32m     91\u001b[0m event_list: tp\u001b[38;5;241m.\u001b[39mList[Event] \u001b[38;5;241m=\u001b[39m [dslice]  \u001b[38;5;66;03m# keep total duration for debug\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39miter():\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# indices relative to the feature start\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     event_list\u001b[38;5;241m.\u001b[39mappend(event)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# figure out overlaps\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/events.py:549\u001b[0m, in \u001b[0;36mEventAccessor.__init__\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame \u001b[38;5;241m=\u001b[39m frame\n\u001b[0;32m--> 549\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/events.py:603\u001b[0m, in \u001b[0;36mEventAccessor.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate the DataFrame of events.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m    DataFrame in which each row has been validated and updated accordingly.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_event, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/events.py:586\u001b[0m, in \u001b[0;36mEventAccessor._validate_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Build event object to run the checks inside the kind-specific Event class\u001b[39;00m\n\u001b[1;32m    585\u001b[0m event_class: tp\u001b[38;5;241m.\u001b[39mType[Event] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCLASS_KIND_MAPPING[event\u001b[38;5;241m.\u001b[39mkind]\n\u001b[0;32m--> 586\u001b[0m event_obj \u001b[38;5;241m=\u001b[39m event_class\u001b[38;5;241m.\u001b[39mfrom_dict(event)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m# Add back fields that were ignored by the Event class\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# event.update(asdict(event_obj))  # Very slow, use dict updating instead\u001b[39;00m\n\u001b[1;32m    590\u001b[0m event \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mevent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39masdict(event_obj)}\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/events.py:53\u001b[0m, in \u001b[0;36mEvent.from_dict\u001b[0;34m(cls, row)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create event from dictionary while ignoring extra parameters.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [f\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields(\u001b[38;5;28mcls\u001b[39m)]})\n",
      "File \u001b[0;32m<string>:9\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, start, duration, modality, language, filepath, offset)\u001b[0m\n",
      "File \u001b[0;32m/mnt/workspace/brainmagick_MICCAI/bm/events.py:131\u001b[0m, in \u001b[0;36mSound.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m     actual_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath)\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    132\u001b[0m     info \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath)\n\u001b[1;32m    133\u001b[0m     actual_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(info\u001b[38;5;241m.\u001b[39mnum_frames \u001b[38;5;241m/\u001b[39m info\u001b[38;5;241m.\u001b[39msample_rate) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset\n",
      "\u001b[0;31mAssertionError\u001b[0m: /home/zubrikhina/brainmagick_MICCAI/data/gwilliams2022/download/stimuli/audio/lw1_0.wav does not exist."
     ]
    }
   ],
   "source": [
    "solver = play.get_solver_from_sig(sig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ALL SOLVERS LOADED\")\n",
    "print(\"now the table.\")\n",
    "\n",
    "print_table_line(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_map(solver):\n",
    "    loader = solver.make_loader(solver.datasets.train)\n",
    "    batch = next(iter(loader)).to(solver.device)\n",
    "    model = solver.model\n",
    "    merger = model.merger\n",
    "    positions = merger.position_getter.get_positions(batch)\n",
    "    embedding = merger.embedding(positions)\n",
    "    meg = batch.meg\n",
    "    B, C, T = meg.shape\n",
    "    score_offset = torch.zeros(B, C, device=meg.device)\n",
    "    score_offset[merger.position_getter.is_invalid(positions)] = float('-inf')\n",
    "    heads = merger.heads[None].expand(B, -1, -1)\n",
    "    scores = torch.einsum(\"bcd,bod->boc\", embedding, heads)\n",
    "    scores += score_offset[:, None]\n",
    "    weights = torch.softmax(scores, dim=2)\n",
    "    \n",
    "    # Weights is of shape [Virtual Channels, Input Channels]\n",
    "    # Each Virtual Channel is a weighted sum over the input channels.\n",
    "    # Positions give the normalized 2d position for each Input channel.\n",
    "    # To get an overall weight for a given input sensor you can for instance do\n",
    "    # weights[0].sum(dim=0)\n",
    "    return weights[0], positions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape, positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
