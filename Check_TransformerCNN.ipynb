{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "652edb42-10cb-48cd-a7a8-0f039157971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import random\n",
    "import typing as tp\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchaudio as ta\n",
    "\n",
    "from bm.models.common import (\n",
    "    ConvSequence, ScaledEmbedding, SubjectLayers,\n",
    "    DualPathRNN, ChannelMerger, ChannelDropout, pad_multiple\n",
    ")\n",
    "from bm.models import SimpleConv\n",
    "from bm.models import CNNTransformer\n",
    "from bm import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c65a65d4-3cb6-4164-88c0-73c8e49c59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleconv={\n",
    "      \"in_channels\": {\"meg\" : 207},\n",
    "      \"out_channels\" :1024,\n",
    "      \"hidden\":\n",
    "        {\"meg\": 320},\n",
    "      \"batch_norm\": True,\n",
    "      \"depth\": 4,\n",
    "      \"dilation_period\": 1,\n",
    "      \"kernel_size\": [3,3,3,3,3,3,3,3,3,3],\n",
    "      \"skip\": True, \n",
    "      \"subject_layers\": False,\n",
    "      \"subject_dim\": 0,\n",
    "      \"complex_out\": False, \n",
    "      \"glu\": 2, \n",
    "      \"glu_context\": 1, \n",
    "      \"merger\": False,\n",
    "      \"initial_linear\": 270,\n",
    "      \"avg_pool_out\" : False,\n",
    "      \"adaptive_pooling_size\" : 1,\n",
    "      \"strides\" : [1,1,1,1,1,1,1,1,1,1],\n",
    "      \"padding\": [1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "      \"gelu\": True,\n",
    "      \"merger_pos_dim\": 2048,\n",
    "      \"auto_padding\" : False,\n",
    "      \"flatten_out\" : True,\n",
    "       \"conv_dropout\" : 0.2,\n",
    "     \"is_deformable_conv\": False,\n",
    "       \"seq_len\" : 361, \n",
    "      \"n_subjects\" : 27,\n",
    "      \"flatten_out_channels\" : 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "599a8940-b8e9-4d43-8591-2203c0043067",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = {\"meg\" : 207}\n",
    "model_chout =270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "306f324c-9d23-4ad1-9932-4e7366d8d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "model = SimpleConv(**simpleconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74640503-7c9e-47d0-b652-0fa37bf8028f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleConv(\n",
       "  (initial_linear): Sequential(\n",
       "    (0): Conv1d(207, 270, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (encoders): ModuleDict(\n",
       "    (meg): ConvSequence(\n",
       "      (sequence): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv1d(270, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (1-2): 2 x Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv1d(320, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (glus): ModuleList(\n",
       "        (0): None\n",
       "        (1): Sequential(\n",
       "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "        (2): None\n",
       "        (3): Sequential(\n",
       "          (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "875883c5-5abe-4b5e-85ad-36d06a81ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch =torch.rand(size=(256, 207, 362))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21dc00c1-c2df-4feb-ac32-55b4ae35372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentBatch():\n",
    "    def __init__(self, indx, batch):\n",
    "        self.subject_index =indx\n",
    "        self.meg = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb8fb472-a161-4bbe-9f9f-78d3420516a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_batch =SegmentBatch(0, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f40506-b2b5-4c0f-b119-8e57ec170d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop & pad:  361\n"
     ]
    }
   ],
   "source": [
    "out =model({\"meg\" : batch}, segment_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9bbc088-e781-42d6-8e7e-094237e34a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': {'meg': 270},\n",
       " 'out_channels': 216,\n",
       " 'hidden': {'meg': 320},\n",
       " 'batch_norm': True,\n",
       " 'depth': 4,\n",
       " 'dilation_period': 1,\n",
       " 'kernel_size': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       " 'skip': True,\n",
       " 'subject_layers': False,\n",
       " 'subject_dim': 0,\n",
       " 'complex_out': False,\n",
       " 'glu': 2,\n",
       " 'glu_context': 1,\n",
       " 'merger': False,\n",
       " 'initial_linear': 270,\n",
       " 'avg_pool_out': False,\n",
       " 'adaptive_pooling_size': 1,\n",
       " 'strides': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'padding': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'gelu': True,\n",
       " 'merger_pos_dim': 2048,\n",
       " 'auto_padding': False,\n",
       " 'flatten_out': True,\n",
       " 'conv_dropout': 0.2,\n",
       " 'is_deformable_conv': False,\n",
       " 'seq_len': 361,\n",
       " 'n_subjects': 27,\n",
       " 'flatten_out_channels': 264}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baebc943-bf43-4b27-ba3e-764a434e7ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 216, 361])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a5dd9a-115d-44d5-93ef-dbe4b9c3bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleconv={\n",
    "      \"in_channels\": {\"meg\" : 207},\n",
    "      \"out_channels\" :216,\n",
    "      \"hidden\":\n",
    "        {\"meg\": 320},\n",
    "      \"batch_norm\": True,\n",
    "      \"depth\": 4,\n",
    "      \"dilation_period\": 1,\n",
    "      \"kernel_size\": [3,3,3,3,3,3,3,3,3,3],\n",
    "      \"skip\": True, \n",
    "      \"subject_layers\": False,\n",
    "      \"subject_dim\": 0,\n",
    "      \"complex_out\": False, \n",
    "      \"glu\": 2, \n",
    "      \"glu_context\": 1, \n",
    "      \"merger\": False,\n",
    "      \"initial_linear\": 270,\n",
    "      \"avg_pool_out\" : False,\n",
    "      \"adaptive_pooling_size\" : 1,\n",
    "      \"strides\" : [1,1,1,1,1,1,1,1,1,1],\n",
    "      \"padding\": [1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "      \"gelu\": True,\n",
    "      \"merger_pos_dim\": 2048,\n",
    "      \"auto_padding\" : False,\n",
    "      \"flatten_out\" : True,\n",
    "       \"conv_dropout\" : 0.2,\n",
    "     \"is_deformable_conv\": False,\n",
    "       \"seq_len\" : 361, \n",
    "      \"n_subjects\" : 27,\n",
    "      \"flatten_out_channels\" : 264}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e02944-f978-47de-a8cd-990a2bd37cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "cnn_transformer = CNNTransformer(in_channels_tranformer=264,out_channels_transformer=1024, dim_ff = 2048, \n",
    "                 nhead =8,\n",
    "                 positional_embedding=False,\n",
    "                 positional_embedding_dropout=0.0, **simpleconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106c3441-7797-41ae-b5a1-8c61234a711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNTransformer(\n",
       "  (initial_linear): Sequential(\n",
       "    (0): Conv1d(207, 270, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (encoders): ModuleDict(\n",
       "    (meg): ConvSequence(\n",
       "      (sequence): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv1d(270, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (1-2): 2 x Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv1d(320, 264, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (glus): ModuleList(\n",
       "        (0): None\n",
       "        (1): Sequential(\n",
       "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "        (2): None\n",
       "        (3): Sequential(\n",
       "          (0): Conv1d(264, 528, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=264, out_features=264, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=264, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=264, bias=True)\n",
       "      (norm1): LayerNorm((264,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((264,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=264, out_features=264, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=264, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=264, bias=True)\n",
       "      (norm1): LayerNorm((264,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((264,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=264, out_features=264, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=264, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=264, bias=True)\n",
       "      (norm1): LayerNorm((264,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((264,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (last): Linear(in_features=264, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed2263bf-7ab1-4eef-8ecb-0acb742306e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 207, 362])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2c7c1d4-1754-4851-9a54-eacb7509fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop & pad:  361\n",
      "torch.Size([256, 264, 361])\n",
      "torch.Size([256, 361, 264])\n"
     ]
    }
   ],
   "source": [
    "out =cnn_transformer({\"meg\" : batch}, segment_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5799b70-e819-4b1f-96b7-ff72ccb8e99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 361, 1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe859ee-f0f5-4ff4-97e3-e11306ad1b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
